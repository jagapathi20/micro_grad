{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c682b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from neural_network import MLP\n",
    "from engine import Value\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e440612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f08253",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5669703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "426343c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "080e93ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(30, [16, 16, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2526cf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(batch_size=None):\n",
    "    if batch_size is None:\n",
    "        Xb, yb = X_train, y_train\n",
    "    else:\n",
    "        ri = np.random.permutation(X.shape[0])[:batch_size]\n",
    "        Xb, yb = X_train[ri], y_train[ri]\n",
    "    inputs = [list(map(Value, xrow)) for xrow in Xb]\n",
    "\n",
    "    y_pred = list(map(model, inputs))\n",
    "\n",
    "    loss = sum((y_p - y) ** 2 for y_p, y in zip(y_pred, yb))\n",
    "    loss *= (1 / 2 * len(y_pred))\n",
    "    lamb = 1e-4\n",
    "    reg_loss = lamb * (sum(p * p for p in model.parameters()))\n",
    "    total_loss = loss + reg_loss\n",
    "\n",
    "    accuracy = [(y > 0) == (y_p.data > 0) for y, y_p in zip(yb, y_pred)]\n",
    "\n",
    "    return total_loss, sum(accuracy) / len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ef36db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss, acc = loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5f7b2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value=2929884.2623871993 0.6659340659340659\n"
     ]
    }
   ],
   "source": [
    "print(total_loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f19beade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss inf accuracy62.857142857142854%\n",
      "step 1 loss inf accuracy37.142857142857146%\n",
      "step 2 loss inf accuracy62.857142857142854%\n",
      "step 3 loss inf accuracy37.142857142857146%\n",
      "step 4 loss inf accuracy62.857142857142854%\n",
      "step 5 loss inf accuracy37.142857142857146%\n",
      "step 6 loss inf accuracy62.857142857142854%\n",
      "step 7 loss inf accuracy37.142857142857146%\n",
      "step 8 loss inf accuracy62.857142857142854%\n",
      "step 9 loss inf accuracy37.142857142857146%\n",
      "step 10 loss inf accuracy62.857142857142854%\n",
      "step 11 loss inf accuracy37.142857142857146%\n",
      "step 12 loss inf accuracy62.857142857142854%\n",
      "step 13 loss inf accuracy37.142857142857146%\n",
      "step 14 loss inf accuracy62.857142857142854%\n",
      "step 15 loss inf accuracy37.142857142857146%\n",
      "step 16 loss inf accuracy62.857142857142854%\n",
      "step 17 loss inf accuracy37.142857142857146%\n",
      "step 18 loss inf accuracy62.857142857142854%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jagapathimallepula/Desktop/projects/micro_grad/engine.py:53: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  other.grad += self.data * out.grad\n",
      "/Users/jagapathimallepula/Desktop/projects/micro_grad/engine.py:85: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  self.grad += (out.data > 0) * out.grad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 19 loss inf accuracy37.142857142857146%\n",
      "step 20 loss nan accuracy37.142857142857146%\n",
      "step 21 loss nan accuracy37.142857142857146%\n",
      "step 22 loss nan accuracy37.142857142857146%\n",
      "step 23 loss nan accuracy37.142857142857146%\n",
      "step 24 loss nan accuracy37.142857142857146%\n",
      "step 25 loss nan accuracy37.142857142857146%\n",
      "step 26 loss nan accuracy37.142857142857146%\n",
      "step 27 loss nan accuracy37.142857142857146%\n",
      "step 28 loss nan accuracy37.142857142857146%\n",
      "step 29 loss nan accuracy37.142857142857146%\n",
      "step 30 loss nan accuracy37.142857142857146%\n",
      "step 31 loss nan accuracy37.142857142857146%\n",
      "step 32 loss nan accuracy37.142857142857146%\n",
      "step 33 loss nan accuracy37.142857142857146%\n",
      "step 34 loss nan accuracy37.142857142857146%\n",
      "step 35 loss nan accuracy37.142857142857146%\n",
      "step 36 loss nan accuracy37.142857142857146%\n",
      "step 37 loss nan accuracy37.142857142857146%\n",
      "step 38 loss nan accuracy37.142857142857146%\n",
      "step 39 loss nan accuracy37.142857142857146%\n",
      "step 40 loss nan accuracy37.142857142857146%\n",
      "step 41 loss nan accuracy37.142857142857146%\n",
      "step 42 loss nan accuracy37.142857142857146%\n",
      "step 43 loss nan accuracy37.142857142857146%\n",
      "step 44 loss nan accuracy37.142857142857146%\n",
      "step 45 loss nan accuracy37.142857142857146%\n",
      "step 46 loss nan accuracy37.142857142857146%\n",
      "step 47 loss nan accuracy37.142857142857146%\n",
      "step 48 loss nan accuracy37.142857142857146%\n",
      "step 49 loss nan accuracy37.142857142857146%\n",
      "step 50 loss nan accuracy37.142857142857146%\n",
      "step 51 loss nan accuracy37.142857142857146%\n",
      "step 52 loss nan accuracy37.142857142857146%\n",
      "step 53 loss nan accuracy37.142857142857146%\n",
      "step 54 loss nan accuracy37.142857142857146%\n",
      "step 55 loss nan accuracy37.142857142857146%\n",
      "step 56 loss nan accuracy37.142857142857146%\n",
      "step 57 loss nan accuracy37.142857142857146%\n",
      "step 58 loss nan accuracy37.142857142857146%\n",
      "step 59 loss nan accuracy37.142857142857146%\n",
      "step 60 loss nan accuracy37.142857142857146%\n",
      "step 61 loss nan accuracy37.142857142857146%\n",
      "step 62 loss nan accuracy37.142857142857146%\n",
      "step 63 loss nan accuracy37.142857142857146%\n",
      "step 64 loss nan accuracy37.142857142857146%\n",
      "step 65 loss nan accuracy37.142857142857146%\n",
      "step 66 loss nan accuracy37.142857142857146%\n",
      "step 67 loss nan accuracy37.142857142857146%\n",
      "step 68 loss nan accuracy37.142857142857146%\n",
      "step 69 loss nan accuracy37.142857142857146%\n",
      "step 70 loss nan accuracy37.142857142857146%\n",
      "step 71 loss nan accuracy37.142857142857146%\n",
      "step 72 loss nan accuracy37.142857142857146%\n",
      "step 73 loss nan accuracy37.142857142857146%\n",
      "step 74 loss nan accuracy37.142857142857146%\n",
      "step 75 loss nan accuracy37.142857142857146%\n",
      "step 76 loss nan accuracy37.142857142857146%\n",
      "step 77 loss nan accuracy37.142857142857146%\n",
      "step 78 loss nan accuracy37.142857142857146%\n",
      "step 79 loss nan accuracy37.142857142857146%\n",
      "step 80 loss nan accuracy37.142857142857146%\n",
      "step 81 loss nan accuracy37.142857142857146%\n",
      "step 82 loss nan accuracy37.142857142857146%\n",
      "step 83 loss nan accuracy37.142857142857146%\n",
      "step 84 loss nan accuracy37.142857142857146%\n",
      "step 85 loss nan accuracy37.142857142857146%\n",
      "step 86 loss nan accuracy37.142857142857146%\n",
      "step 87 loss nan accuracy37.142857142857146%\n",
      "step 88 loss nan accuracy37.142857142857146%\n",
      "step 89 loss nan accuracy37.142857142857146%\n",
      "step 90 loss nan accuracy37.142857142857146%\n",
      "step 91 loss nan accuracy37.142857142857146%\n",
      "step 92 loss nan accuracy37.142857142857146%\n",
      "step 93 loss nan accuracy37.142857142857146%\n",
      "step 94 loss nan accuracy37.142857142857146%\n",
      "step 95 loss nan accuracy37.142857142857146%\n",
      "step 96 loss nan accuracy37.142857142857146%\n",
      "step 97 loss nan accuracy37.142857142857146%\n",
      "step 98 loss nan accuracy37.142857142857146%\n",
      "step 99 loss nan accuracy37.142857142857146%\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "    # forward\n",
    "    total_loss, acc = loss()\n",
    "\n",
    "    # backward\n",
    "    model.zero_grad()\n",
    "    total_loss.backward()\n",
    "\n",
    "    # update\n",
    "    learning_rate = 1.0 - 0.9 * k / 100\n",
    "    for p in model.parameters():\n",
    "        p.data -= learning_rate * p.grad\n",
    "\n",
    "    if k % 1 == 0:\n",
    "        print(f\"step {k} loss {total_loss.data} accuracy{acc * 100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88066ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
